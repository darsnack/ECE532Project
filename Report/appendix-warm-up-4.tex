For the thought experiment, the pixel at (0, 0) is white for all time, so we can use the value 0 to represent it. Similarly, a pixel in the same row as the black box is white almost all of the time, except it is black for one time instance. Therefore, we can just use a pixel value of 0 to represent it, and we would be write most of the time.

The matrix we are trying to form looks like this:
$$\left[\begin{matrix}
	0 & 0 & \ldots & 0 & 0 \\
	0 & 1 & \ldots & 0 & 0 \\
	\vdots & \vdots & \vdots & \vdots & \vdots \\
	0 & 0 & \ddots & 0 & 0 \\
	0 & 0 & \ldots & 1 & 0 \\
	0 & 0 & \ldots & 0 & 0
\end{matrix}\right]$$
It is a matrix with a small identity matrix in the center that is surrounded by zeros all around. If we look at each column of this matrix, it is either all zeros, or it is zeros everywhere except one element is one. If we can only use one vector to represent these vectors, we would choose a vector of all zeros, because placing a single 1 in any position would only be correct for one column and wrong for all others.

Notice that this matrix has reduced an entire video to just two dimensions -- position along the columns and time along the rows. Applying the SVD techniques to this matrix will do what we have been doing in this warm-up exercise -- it tries to use a single vector to represent several positions in the image across time. These vectors may not be all ones or zeros like we have been constructing. Think about positions in the image whose \textit{change} over time is similar. The background pixel positions are all subject to the same change over time (lighting, etc). So, a single unit vector can represent that normalized change. Then each pixel is just a scalar multiple of that vector. So what does using the SVD to find a low-rank approximation to this matrix do? Simply, it tries to represent the matrix using only a few basis vectors. The number of basis vectors is the determined by the rank chosen for the low-rank approximation.